{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY0IUGtZawl3"
      },
      "source": [
        "# RAG graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9YJSCWBawl7",
        "outputId": "08189f53-b4ef-496c-f4fe-5ea7f90e0508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Downloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.9.0\n"
          ]
        }
      ],
      "source": [
        "pip install transformers faiss-cpu networkx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWvpD2Czawl-",
        "outputId": "6ddd8417-fe2a-4ad3-8ab4-b0306e8d0dcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XYisOLEawl-"
      },
      "source": [
        "## Create Graph KB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qUzfq45Mawl-"
      },
      "outputs": [],
      "source": [
        "# Initialize a directed graph\n",
        "G = nx.DiGraph()\n",
        "\n",
        "# Add Machine Nodes with Attributes\n",
        "G.add_node(\"LaserCutter_1\", node_type=\"Machine\", model=\"LC-200\", manufacturer=\"Brand A\")\n",
        "G.add_node(\"LaserCutter_2\", node_type=\"Machine\", model=\"LC-300\", manufacturer=\"Brand B\")\n",
        "\n",
        "# Add KPI Nodes with Descriptions and Normal Ranges\n",
        "G.add_node(\"WorkingTime\", node_type=\"KPI\", description=\"Time actively working\", unit=\"seconds\", normal_min=6, normal_max=10)\n",
        "G.add_node(\"IdleTime\", node_type=\"KPI\", description=\"Time idle but available\", unit=\"seconds\", normal_min=1, normal_max=4)\n",
        "G.add_node(\"OfflineTime\", node_type=\"KPI\", description=\"Time offline and not available\", unit=\"seconds\", normal_min=0, normal_max=2)\n",
        "\n",
        "# Add Directed Relationships (Edges) Between Machines and KPIs\n",
        "G.add_edge(\"LaserCutter_1\", \"WorkingTime\", relationship=\"measures\")\n",
        "G.add_edge(\"LaserCutter_1\", \"IdleTime\", relationship=\"measures\")\n",
        "G.add_edge(\"LaserCutter_1\", \"OfflineTime\", relationship=\"measures\")\n",
        "\n",
        "G.add_edge(\"LaserCutter_2\", \"WorkingTime\", relationship=\"measures\")\n",
        "G.add_edge(\"LaserCutter_2\", \"IdleTime\", relationship=\"measures\")\n",
        "G.add_edge(\"LaserCutter_2\", \"OfflineTime\", relationship=\"measures\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz0f2cZSawl_"
      },
      "source": [
        "## Create embeddings for each node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byFVJP8Sawl_",
        "outputId": "ee3f8686-f08a-494b-dedf-50fb4eb0d829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LaserCutter_1: Machine type Machine, model LC-200, manufactured by Brand A. Measures KPIs: WorkingTime, IdleTime, OfflineTime.\n",
            "LaserCutter_2: Machine type Machine, model LC-300, manufactured by Brand B. Measures KPIs: WorkingTime, IdleTime, OfflineTime.\n",
            "WorkingTime: KPI WorkingTime, measures Time actively working in seconds. Normal range is 6 to 10. Measured by machines: LaserCutter_1, LaserCutter_2.\n",
            "IdleTime: KPI IdleTime, measures Time idle but available in seconds. Normal range is 1 to 4. Measured by machines: LaserCutter_1, LaserCutter_2.\n",
            "OfflineTime: KPI OfflineTime, measures Time offline and not available in seconds. Normal range is 0 to 2. Measured by machines: LaserCutter_1, LaserCutter_2.\n"
          ]
        }
      ],
      "source": [
        "# Function to generate descriptions automatically\n",
        "def generate_descriptions(graph):\n",
        "    descriptions = {}\n",
        "\n",
        "    for node in graph.nodes(data=True):\n",
        "        node_name, attributes = node\n",
        "        node_type = attributes.get(\"node_type\")\n",
        "\n",
        "        if node_type == \"Machine\":\n",
        "            # Find KPIs measured by this machine\n",
        "            kpis = [target for source, target, data in graph.edges(data=True) if source == node_name and data[\"relationship\"] == \"measures\"]\n",
        "            kpi_list = \", \".join(kpis)\n",
        "\n",
        "            # Generate description using template\n",
        "            descriptions[node_name] = (\n",
        "                f\"Machine type {attributes.get('node_type')}, model {attributes.get('model')}, \"\n",
        "                f\"manufactured by {attributes.get('manufacturer')}. Measures KPIs: {kpi_list}.\"\n",
        "            )\n",
        "\n",
        "        elif node_type == \"KPI\":\n",
        "            # Find machines that measure this KPI\n",
        "            machines = [source for source, target, data in graph.edges(data=True) if target == node_name and data[\"relationship\"] == \"measures\"]\n",
        "            machine_list = \", \".join(machines)\n",
        "\n",
        "            # Generate description using template\n",
        "            descriptions[node_name] = (\n",
        "                f\"KPI {node_name}, measures {attributes.get('description')} in {attributes.get('unit')}. \"\n",
        "                f\"Normal range is {attributes.get('normal_min')} to {attributes.get('normal_max')}. \"\n",
        "                f\"Measured by machines: {machine_list}.\"\n",
        "            )\n",
        "\n",
        "    return descriptions\n",
        "\n",
        "# Generate and print descriptions for all nodes\n",
        "generated_descriptions = generate_descriptions(G)\n",
        "for node, desc in generated_descriptions.items():\n",
        "    print(f\"{node}: {desc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6XTVp9cnSCC",
        "outputId": "ecc2ed74-6619-4409-c8df-085ff2ea0734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: The machines include LaserCut , LaserCut LC-300 , LaserCut LaserCut1 and LaserCut 2.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "# Load the Sentence Transformer model for embedding-based retrieval\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Assuming `generated_descriptions` contains descriptions for each node\n",
        "node_embeddings = {node: embedder.encode(description) for node, description in generated_descriptions.items()}\n",
        "\n",
        "# Convert node embeddings to a matrix for FAISS\n",
        "embeddings_matrix = np.array(list(node_embeddings.values())).astype(\"float32\")\n",
        "embedding_dim = embeddings_matrix.shape[1]\n",
        "\n",
        "# Initialize FAISS index with the correct dimension\n",
        "index = faiss.IndexFlatL2(embedding_dim)\n",
        "index.add(embeddings_matrix)\n",
        "\n",
        "# Map node names to their index positions in FAISS\n",
        "node_to_id = {node: idx for idx, node in enumerate(node_embeddings.keys())}\n",
        "id_to_node = {idx: node for node, idx in node_to_id.items()}\n",
        "\n",
        "# Function to retrieve top-k nodes using SentenceTransformer embeddings and FAISS\n",
        "def retrieve_top_k_nodes(query, top_k=3):\n",
        "    query_embedding = embedder.encode(query).reshape(1, -1).astype(\"float32\")\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "    retrieved_nodes = [\n",
        "        {\n",
        "            \"node\": id_to_node[idx],\n",
        "            \"description\": generated_descriptions[id_to_node[idx]],\n",
        "            \"distance\": distances[0][i]\n",
        "        }\n",
        "        for i, idx in enumerate(indices[0])\n",
        "    ]\n",
        "    return retrieved_nodes\n",
        "\n",
        "# Set up the FLAN-T5 model for text generation\n",
        "model_name = \"google/flan-t5-large\"  # or \"google/flan-t5-xl\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Create a text generation pipeline with FLAN-T5\n",
        "generator_pipeline = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=0 if torch.cuda.is_available() else -1,\n",
        "    max_new_tokens=100,\n",
        "    do_sample=True\n",
        ")\n",
        "\n",
        "# Example query for retrieval\n",
        "query = \"How many LaserCutting machines are there?\"\n",
        "retrieved_nodes = retrieve_top_k_nodes(query)\n",
        "\n",
        "# Combine descriptions into a single context string\n",
        "context = \"\\n\".join([f\"{node['node']}: {node['description']}\" for node in retrieved_nodes])\n",
        "\n",
        "# Format the prompt with the context and query for the FLAN-T5 model\n",
        "prompt = f\"\"\"\n",
        "Please answer the following question based on the provided information. Offer a clear and thorough explanation that directly answers the question and includes any important details or context for a better understanding.\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Additional information:\n",
        "{context}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "# Generate the response\n",
        "response = generator_pipeline(prompt)\n",
        "print(\"Response:\", response[0][\"generated_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGKxCxKMjG0W",
        "outputId": "ee842a87-4cfd-4652-d88f-22e601f61de5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WorkingTime: KPI WorkingTime, measures Time actively working in seconds. Normal range is 6 to 10. Measured by machines: LaserCutter_1, LaserCutter_2.\n",
            "IdleTime: KPI IdleTime, measures Time idle but available in seconds. Normal range is 1 to 4. Measured by machines: LaserCutter_1, LaserCutter_2.\n",
            "LaserCutter_2: Machine type Machine, model LC-300, manufactured by Brand B. Measures KPIs: WorkingTime, IdleTime, OfflineTime.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "SA_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}